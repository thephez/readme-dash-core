{
 "metadata": {
  "image": [],
  "title": "",
  "description": ""
 },
 "api": {
  "method": "get",
  "url": "",
  "auth": "required",
  "results": {
   "codes": [
    {
     "status": 200,
     "language": "json",
     "code": "{}",
     "name": ""
    },
    {
     "status": 400,
     "language": "json",
     "code": "{}",
     "name": ""
    }
   ]
  },
  "params": []
 },
 "next": {
  "description": "",
  "pages": [
   {
    "type": "doc",
    "icon": "file-text-o",
    "name": "Future Proposals",
    "slug": "core-guide-operating-modes-future-proposals",
    "category": "Core Guides"
   }
  ]
 },
 "title": "Simplified Payment Verification (SPV)",
 "updates": [],
 "type": "basic",
 "slug": "core-guide-operating-modes-simplified-payment-verification-spv",
 "excerpt": "",
 "body": "An alternative approach detailed in the [original Bitcoin paper](https://bitcoin.org/en/bitcoin-paper) is a client that only downloads the <<glossary:headers>> of <<glossary:blocks>> during the initial syncing process and then requests <<glossary:transactions>> from full <<glossary:nodes>> as needed. This scales linearly with the height of the <<glossary:block chain>> at only 80 bytes per block header, or up to 16.8MB per year, regardless of total block size.\n\nAs described in the white paper, the <<glossary:merkle root>> in the block header along with a merkle branch can prove to the SPV client that the transaction in question is embedded in a block in the block chain. This does not guarantee validity of the transactions that are embedded. Instead it demonstrates the amount of work required to perform a double-spend attack.\n\nThe block's depth in the block chain corresponds to the cumulative <<glossary:difficulty>> that has been performed to build on top of that particular block. The SPV client knows the merkle root and associated transaction information, and requests the respective merkle branch from a full node. Once the merkle branch has been retrieved, proving the existence of the transaction in the block, the SPV client can then look to block *depth* as a proxy for transaction validity and security. The cost of an attack on a user by a malicious node who inserts an invalid transaction grows with the cumulative difficulty built on top of that block, since the malicious node alone will be mining this forged chain.\n\n# Potential SPV Weaknesses\n\nIf implemented naively, an SPV client has a few important weaknesses.\n\nFirst, while the SPV client can not be easily fooled into thinking a transaction is in a block when it is not, the reverse is not true. A full node can simply lie by omission, leading an SPV client to believe a transaction has not occurred. This can be considered a form of Denial of Service. One mitigation strategy is to connect to a number of full <<glossary:nodes>>, and send the requests to each node. However this can be defeated by network partitioning or Sybil attacks, since identities are essentially free, and can be bandwidth intensive. Care must be taken to ensure the client is not cut off from honest nodes.\n\nSecond, the SPV client only requests transactions from full nodes corresponding to keys it owns. If the SPV client downloads all blocks and then discards unneeded ones, this can be extremely bandwidth intensive. If they simply ask full nodes for blocks with specific transactions, this allows full nodes a complete view of the public <<glossary:addresses>> that correspond to the user. This is a large privacy leak, and allows for tactics such as denial of service for clients, users, or addresses that are disfavored by those running full nodes, as well as trivial linking of funds. A client could simply spam many fake transaction requests, but this creates a large strain on the SPV client, and can end up defeating the purpose of thin clients altogether.\n\nTo mitigate the latter issue, Bloom filters have been implemented as a method of obfuscation and compression of block data requests.\n\n# Bloom Filters\n\nA <<glossary:bloom filter>> is a space-efficient probabilistic data structure that is used to test membership of an element. The data structure achieves great data compression at the expense of a prescribed false positive rate.\n\nA Bloom filter starts out as an array of n bits all set to 0. A set of k random hash functions are chosen, each of which output a single integer between the range of 1 and n.\n\nWhen adding an element to the Bloom filter, the element is hashed k times separately, and for each of the k outputs, the corresponding Bloom filter bit at that index is set to 1.\n\nQuerying of the Bloom filter is done by using the same hash functions as before. If all k bits accessed in the bloom filter are set to 1, this demonstrates with high probability that the element lies in the set. Clearly, the k indices could have been set to 1 by the addition of a combination of other elements in the domain, but the parameters allow the user to choose the acceptable false positive rate.\n\nRemoval of elements can only be done by scrapping the bloom filter and re-creating it from scratch.\n\n# Application Of Bloom Filters\n\nRather than viewing the false positive rates as a liability, it is used to create a tunable parameter that represents the desired privacy level and bandwidth trade-off. A SPV client creates their Bloom filter and sends it to a full node using the [`filterload` message](core-ref-p2p-network-control-messages#filterload), which sets the filter for which transactions are desired. The [`filteradd` message](core-ref-p2p-network-control-messages#filteradd) allows addition of desired data to the filter without needing to send a totally new Bloom filter, and the [`filterclear` message](core-ref-p2p-network-control-messages#filterclear) allows the connection to revert to standard block discovery mechanisms. If the filter has been loaded, then full nodes will send a modified form of blocks, called a <<glossary:merkle block>>. The merkle block is simply the block header with the merkle branch associated with the set Bloom filter.\n\nAn SPV client can not only add transactions as elements to the filter, but also <<glossary:public keys>>, data from signature scripts and pubkey scripts, and more. This enables <<glossary:P2SH>> transaction finding.\n\nIf a user is more privacy-conscious, he can set the Bloom filter to include more false positives, at the expense of extra bandwidth used for transaction discovery. If a user is on a tight bandwidth budget, he can set the false-positive rate to low, knowing that this will allow full nodes a clear view of what transactions are associated with his client.\n\n**Resources:** [DashJ](https://github.com/HashEngineering/dashj), a Java implementation of Dash based on BitcoinJ that uses the SPV security model and Bloom filters. Used in many Android wallets.\n\nBloom filters were standardized for use via [BIP37](https://github.com/bitcoin/bips/blob/master/bip-0037.mediawiki). Review the BIP for implementation details.",
 "order": 1,
 "isReference": false,
 "hidden": false,
 "sync_unique": "",
 "link_url": "",
 "link_external": false,
 "pendingAlgoliaPublish": false,
 "createdAt": "2019-10-28T13:45:54.394Z",
 "updatedAt": "2020-05-28T20:44:14.291Z",
 "_id": "5e96055329a18c0025d39238",
 "version": "5e96055329a18c0025d39261",
 "project": "5daf2e65f4109c0040fd51e1",
 "user": "5af39863989da435b05d284d",
 "parentDoc": "5e96055329a18c0025d39236",
 "category": "5e96055329a18c0025d391e3",
 "__v": 1,
 "isApi": false,
 "id": "5e96055329a18c0025d39238",
 "body_html": "<div class=\"magic-block-textarea\"><p>An alternative approach detailed in the <a href=\"https://bitcoin.org/en/bitcoin-paper\">original Bitcoin paper</a> is a client that only downloads the &lt;&lt;glossary:headers&gt;&gt; of &lt;&lt;glossary:blocks&gt;&gt; during the initial syncing process and then requests &lt;&lt;glossary:transactions&gt;&gt; from full &lt;&lt;glossary:nodes&gt;&gt; as needed. This scales linearly with the height of the &lt;&lt;glossary:block chain&gt;&gt; at only 80 bytes per block header, or up to 16.8MB per year, regardless of total block size.</p>\n<p>As described in the white paper, the &lt;&lt;glossary:merkle root&gt;&gt; in the block header along with a merkle branch can prove to the SPV client that the transaction in question is embedded in a block in the block chain. This does not guarantee validity of the transactions that are embedded. Instead it demonstrates the amount of work required to perform a double-spend attack.</p>\n<p>The block&#39;s depth in the block chain corresponds to the cumulative &lt;&lt;glossary:difficulty&gt;&gt; that has been performed to build on top of that particular block. The SPV client knows the merkle root and associated transaction information, and requests the respective merkle branch from a full node. Once the merkle branch has been retrieved, proving the existence of the transaction in the block, the SPV client can then look to block <em>depth</em> as a proxy for transaction validity and security. The cost of an attack on a user by a malicious node who inserts an invalid transaction grows with the cumulative difficulty built on top of that block, since the malicious node alone will be mining this forged chain.</p>\n<h1 class=\"header-scroll\"><div class=\"anchor waypoint\" id=\"section-potential-spv-weaknesses\"></div>Potential SPV Weaknesses<a class=\"fa fa-anchor\" href=\"#section-potential-spv-weaknesses\"></a></h1>\n<p>If implemented naively, an SPV client has a few important weaknesses.</p>\n<p>First, while the SPV client can not be easily fooled into thinking a transaction is in a block when it is not, the reverse is not true. A full node can simply lie by omission, leading an SPV client to believe a transaction has not occurred. This can be considered a form of Denial of Service. One mitigation strategy is to connect to a number of full &lt;&lt;glossary:nodes&gt;&gt;, and send the requests to each node. However this can be defeated by network partitioning or Sybil attacks, since identities are essentially free, and can be bandwidth intensive. Care must be taken to ensure the client is not cut off from honest nodes.</p>\n<p>Second, the SPV client only requests transactions from full nodes corresponding to keys it owns. If the SPV client downloads all blocks and then discards unneeded ones, this can be extremely bandwidth intensive. If they simply ask full nodes for blocks with specific transactions, this allows full nodes a complete view of the public &lt;&lt;glossary:addresses&gt;&gt; that correspond to the user. This is a large privacy leak, and allows for tactics such as denial of service for clients, users, or addresses that are disfavored by those running full nodes, as well as trivial linking of funds. A client could simply spam many fake transaction requests, but this creates a large strain on the SPV client, and can end up defeating the purpose of thin clients altogether.</p>\n<p>To mitigate the latter issue, Bloom filters have been implemented as a method of obfuscation and compression of block data requests.</p>\n<h1 class=\"header-scroll\"><div class=\"anchor waypoint\" id=\"section-bloom-filters\"></div>Bloom Filters<a class=\"fa fa-anchor\" href=\"#section-bloom-filters\"></a></h1>\n<p>A &lt;&lt;glossary:bloom filter&gt;&gt; is a space-efficient probabilistic data structure that is used to test membership of an element. The data structure achieves great data compression at the expense of a prescribed false positive rate.</p>\n<p>A Bloom filter starts out as an array of n bits all set to 0. A set of k random hash functions are chosen, each of which output a single integer between the range of 1 and n.</p>\n<p>When adding an element to the Bloom filter, the element is hashed k times separately, and for each of the k outputs, the corresponding Bloom filter bit at that index is set to 1.</p>\n<p>Querying of the Bloom filter is done by using the same hash functions as before. If all k bits accessed in the bloom filter are set to 1, this demonstrates with high probability that the element lies in the set. Clearly, the k indices could have been set to 1 by the addition of a combination of other elements in the domain, but the parameters allow the user to choose the acceptable false positive rate.</p>\n<p>Removal of elements can only be done by scrapping the bloom filter and re-creating it from scratch.</p>\n<h1 class=\"header-scroll\"><div class=\"anchor waypoint\" id=\"section-application-of-bloom-filters\"></div>Application Of Bloom Filters<a class=\"fa fa-anchor\" href=\"#section-application-of-bloom-filters\"></a></h1>\n<p>Rather than viewing the false positive rates as a liability, it is used to create a tunable parameter that represents the desired privacy level and bandwidth trade-off. A SPV client creates their Bloom filter and sends it to a full node using the <a href=\"core-ref-p2p-network-control-messages#filterload\"><code>filterload</code> message</a>, which sets the filter for which transactions are desired. The <a href=\"core-ref-p2p-network-control-messages#filteradd\"><code>filteradd</code> message</a> allows addition of desired data to the filter without needing to send a totally new Bloom filter, and the <a href=\"core-ref-p2p-network-control-messages#filterclear\"><code>filterclear</code> message</a> allows the connection to revert to standard block discovery mechanisms. If the filter has been loaded, then full nodes will send a modified form of blocks, called a &lt;&lt;glossary:merkle block&gt;&gt;. The merkle block is simply the block header with the merkle branch associated with the set Bloom filter.</p>\n<p>An SPV client can not only add transactions as elements to the filter, but also &lt;&lt;glossary:public keys&gt;&gt;, data from signature scripts and pubkey scripts, and more. This enables &lt;&lt;glossary:P2SH&gt;&gt; transaction finding.</p>\n<p>If a user is more privacy-conscious, he can set the Bloom filter to include more false positives, at the expense of extra bandwidth used for transaction discovery. If a user is on a tight bandwidth budget, he can set the false-positive rate to low, knowing that this will allow full nodes a clear view of what transactions are associated with his client.</p>\n<p><strong>Resources:</strong> <a href=\"https://github.com/HashEngineering/dashj\">DashJ</a>, a Java implementation of Dash based on BitcoinJ that uses the SPV security model and Bloom filters. Used in many Android wallets.</p>\n<p>Bloom filters were standardized for use via <a href=\"https://github.com/bitcoin/bips/blob/master/bip-0037.mediawiki\">BIP37</a>. Review the BIP for implementation details.</p>\n\n</div>"
}